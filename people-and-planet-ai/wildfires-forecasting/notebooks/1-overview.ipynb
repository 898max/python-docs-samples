{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "j1pdgkM2PA9a",
   "metadata": {
    "cellView": "form",
    "id": "j1pdgkM2PA9a"
   },
   "outputs": [],
   "source": [
    "#@title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
    "\n",
    "# Licensed to the Apache Software Foundation (ASF) under one\n",
    "# or more contributor license agreements. See the NOTICE file\n",
    "# distributed with this work for additional information\n",
    "# regarding copyright ownership. The ASF licenses this file\n",
    "# to you under the Apache License, Version 2.0 (the\n",
    "# \"License\"); you may not use this file except in compliance\n",
    "# with the License. You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing,\n",
    "# software distributed under the License is distributed on an\n",
    "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
    "# KIND, either express or implied. See the License for the\n",
    "# specific language governing permissions and limitations\n",
    "# under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orng0uT9-8iT",
   "metadata": {
    "id": "orng0uT9-8iT"
   },
   "source": [
    "# 🔥 Wildfire spread forecasting -- Overview\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GoogleCloudPlatform/python-docs-samples/blob/main/people-and-planet-ai/wildfires-forecasting/notebooks/1-overview.ipynb)\n",
    "\n",
    "In 2021, wildfires destroyed [7 million acres of wildland](https://www.ncei.noaa.gov/access/monitoring/monthly-report/fire/202113)--roughly the same area as the state of Massachusetts. These wildfires destroyed homes, towns, and people's lives.\n",
    "\n",
    "<figure>\n",
    "<img alt=\"Exterior image of a house mostly destroyed by flames\"\n",
    "     src=\"https://media.cnn.com/api/v1/images/stellar/prod/200908110238-07-wildfires-0907-malden-wa.jpg?q=x_17,y_443,h_876,w_1556,c_crop/h_720,w_1280\"/>\n",
    "<figcaption><i>Figure. The 2020 Babb Road wildfire destroying a home in Malden, WA</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "For a wildfire to catch hold and spread, a set of conditions must exist in an environment. These conditions have been measured and recorded in multiple sources--sources that are available in Earth Engine. Imagine if you could build a ML model that can predict the likelihood and spread of wildfires!\n",
    "\n",
    "This sample is broken into the following notebooks:\n",
    "\n",
    "* 🧭 **Overview**. Go through what we want to achieve and explore the data we want to use as inputs and outputs for our model.\n",
    "* 🗄️ [**Create the dataset**](https://colab.research.google.com/github/GoogleCloudPlatform/python-docs-samples/blob/main/people-and-planet-ai/wildfires-forecasting/notebooks/2-dataset.ipynb) Use [Apache Beam](https://beam.apache.org/) to fetch data from [Earth Engine](https://earthengine.google.com/) and create a dataset for our model in [Dataflow](https://cloud.google.com/dataflow).\n",
    "* 🧠 **Train the model**: Build a simple _Fully Convolutional Network_ in [PyTorch](https://pytorch.org/) and train it in [Vertex AI](https://cloud.google.com/vertex-ai/docs/training/custom-training) with the dataset we created.\n",
    "* 🔮 **Model predictions**: Get predictions from the model with data it has never seen before.\n",
    "\n",
    "This sample leverages geospatial satellite and topographical data from [Google Earth Engine](https://earthengine.google.com/). Using satellite imagery, you'll build and train a model for predicting the potentials spread of a \"current\" wildfire.\n",
    "\n",
    "+ ⏲️ Time estimate: TT hours\n",
    "+ 💰 Cost estimate: Around \\\\$DD USD (free if you use \\\\$300 Cloud credits)\n",
    "\n",
    "💚 This is one of many machine learning how-to samples inspired from real climate solutions aired on the People and Planet AI 🎥 series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jsWGZW_fUJjN",
   "metadata": {
    "id": "jsWGZW_fUJjN"
   },
   "source": [
    "## 📒 Using this interactive notebook\n",
    "\n",
    "Click the **run** icons ▶️ of each section within this notebook.\n",
    "\n",
    "![Run cell](data/images/run-cell.png)\n",
    "\n",
    "> 💡 Alternatively, you can run the currently selected cell with `Ctrl + Enter` (or `⌘ + Enter` in a Mac).\n",
    "\n",
    "This **notebook code lets you train and deploy an ML model** from end-to-end. When you run a code cell, the code runs in the notebook's runtime, so you're not making any changes to your personal computer.\n",
    "\n",
    "> ⚠️ **To avoid any errors**, wait for each section to finish in their order before clicking the next “run” icon.\n",
    "\n",
    "This sample must be connected to a **Google Cloud project**, but nothing else is needed other than your Google Cloud project.\n",
    "\n",
    "You can use an existing project or you can create a new Cloud project [with cloud credits for free.](https://cloud.google.com/free/docs/gcp-free-tier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DgtZrFNdP3lv",
   "metadata": {
    "id": "DgtZrFNdP3lv"
   },
   "source": [
    "## 🎬 Before you begin\n",
    "\n",
    "Let's start by cloning the GitHub repository and installing some dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8630578-6629-4a04-a08b-98b9d2577ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's get the code from GitHub and navigate to the sample.\n",
    "!git clone https://github.com/GoogleCloudPlatform/python-docs-samples.git\n",
    "%cd python-docs-samples/people-and-planet-ai/weather-forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fUX87ic-uNNI",
   "metadata": {
    "id": "fUX87ic-uNNI"
   },
   "source": [
    "Next, we have to authenticate Earth Engine and initialize it.\n",
    "Since we've already authenticated to this [Colab](https://www.youtube.com/watch?v=rNgswRZ2C1Y) and saved our credentials as the [Google default credentials](https://google-auth.readthedocs.io/en/master/reference/google.auth.html#google.auth.default),\n",
    "we can reuse those credentials for Earth Engine.\n",
    "\n",
    "> 💡 Since we're making **large amounts of automated requests to Earth Engine**, we want to use the\n",
    "[high-volume endpoint](https://developers.google.com/earth-engine/cloud/highvolume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3TV2ZvLH17If",
   "metadata": {
    "id": "3TV2ZvLH17If"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import google.auth\n",
    "\n",
    "def ee_init() -> None:\n",
    "    \"\"\"Authenticate and initialize Earth Engine with the default credentials.\"\"\"\n",
    "    # Use the Earth Engine High Volume endpoint.\n",
    "    #   https://developers.google.com/earth-engine/cloud/highvolume\n",
    "    credentials, _ = google.auth.default(\n",
    "        scopes=[\n",
    "            \"https://www.googleapis.com/auth/cloud-platform\",\n",
    "            \"https://www.googleapis.com/auth/earthengine\",\n",
    "        ]\n",
    "    )\n",
    "    ee.Initialize(\n",
    "        credentials,\n",
    "        project=project,\n",
    "        opt_url=\"https://earthengine-highvolume.googleapis.com\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "U9JvRARMaq9r",
   "metadata": {
    "id": "U9JvRARMaq9r"
   },
   "outputs": [],
   "source": [
    "ee_init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6V2XkHeNNMb_",
   "metadata": {
    "id": "6V2XkHeNNMb_"
   },
   "source": [
    "# 📚 Understand the data\n",
    "\n",
    "Before we begin, let's consider what we want to achieve and the datasets we chose for that purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GkVANXLpZCnd",
   "metadata": {
    "id": "GkVANXLpZCnd"
   },
   "source": [
    "## 🎯 **Goal**: Time series forecasting and image segmentation\n",
    "\n",
    "The goal of our model is to use satellite images to analyze the likelihood and potential spread of wildfires for a given geographical region. The output layer will combine a time series forecast (likelihood of fire to spread) and a classification (on fire or not on fire)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqGsEZBf6ASC",
   "metadata": {
    "id": "aqGsEZBf6ASC"
   },
   "source": [
    "## 🛰 Inputs: Satellite images\n",
    "\n",
    "To achieve our goal, we must combine multiple geographical datasets into a single dataset (or map in this case). Each input--also known as \"features\" or \"independent variables\"--will be stored as a single band within the resulting map. The following list shows the datasets used for this example:\n",
    "\n",
    "* **USGS/SRTMGL1_003**: NASA SRTM Digital Elevation 30m\n",
    "* **GRIDMET/DROUGHT**: CONUS Drought Indices\n",
    "* **ECMWF/ERA5/DAILY**: Daily Aggregates - Latest Climate Reanalysis Produced by ECMWF / Copernicus Climate Change Service\n",
    "* **IDAHO_EPSCOR/GRIDMET**: University of Idaho Gridded Surface Meteorological Dataset\n",
    "* **CIESIN/GPWv411/GPW_Population_Density**: Population Density (Gridded Population of the World Version 4.11)\n",
    "\n",
    "The following table shows the model input variables, the source dataset, and the symbols used for variable in our model.\n",
    "\n",
    "| Feature | Original Source | Variable name |\n",
    "| --------|:----------------|:--------------|\n",
    "| Elevation | `USGS/SRTMGL1_003` | `elevation` |\n",
    "| Palmer Drought Severity Index | `GRIDMET/DROUGHT` | `psdi` |\n",
    "| Avg air temperature at 2m height | `ECMWF/ERA5/DAILY` | `mean_2m_air_temperature` |\n",
    "| Total precipitation | `ECMWF/ERA5/DAILY` | `total_precipitation` |\n",
    "| 10m u-component of wind (daily avg) | `ECMWF/ERA5/DAILY` | `u_component_of_wind_10m` |\n",
    "| 10m v-component of wind (daily avg) | `ECMWF/ERA5/DAILY` | `v_component_of_wind_10m'` |\n",
    "|\n",
    "| Precipatation amount | `IDAHO_EPSCOR/GRIDMET` | `pr` |\n",
    "| Specific humidity | `IDAHO_EPSCOR/GRIDMET` | `sph` |\n",
    "| Wind direction | `IDAHO_EPSCOR/GRIDMET` | `th` |\n",
    "| Minimum temperature | `IDAHO_EPSCOR/GRIDMET` | `tmmn` |\n",
    "| Maximum temperature | `IDAHO_EPSCOR/GRIDMET` | `tmmx` |\n",
    "| Wind velocity at 10m | `IDAHO_EPSCOR/GRIDMET` | `vs` |\n",
    "| Energy release component | `IDAHO_EPSCOR/GRIDMET` | `erc` |\n",
    "| Population density (per square km) | `CIESIN/GPWv411/GPW_Population_Density` | `population_density` |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "JNpQO_6UQDOt",
   "metadata": {
    "id": "JNpQO_6UQDOt"
   },
   "outputs": [],
   "source": [
    "INPUTS = {\n",
    "    'USGS/SRTMGL1_003': [\"elevation\"],\n",
    "    'GRIDMET/DROUGHT': [\"psdi\"],\n",
    "    'ECMWF/ERA5/DAILY': [\n",
    "         'mean_2m_air_temperature',\n",
    "         'total_precipitation',\n",
    "         'u_component_of_wind_10m',\n",
    "         'v_component_of_wind_10m'],\n",
    "    'IDAHO_EPSCOR/GRIDMET': [\n",
    "         'pr',\n",
    "         'sph',\n",
    "         'th',\n",
    "         'tmmn',\n",
    "         'tmmx',\n",
    "         'vs',\n",
    "         'erc'],\n",
    "    'CIESIN/GPWv411/GPW_Population_Density': ['population_density'],\n",
    "    'MODIS/006/MOD14A1': ['FireMask']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s_j0UGCkZavj",
   "metadata": {
    "id": "s_j0UGCkZavj"
   },
   "source": [
    "## 🗺 **Outputs**: Land cover map\n",
    "\n",
    "Finally, we need to give the model a set of labels to apply to each section of the map. These labels tell the training program (Tensorflow) what we want to infer from the previous data. In other words, this dataset represents the \"dependent variable\" that our model attempts to predict. For our model, we will use the \"Terra Thermal Anomalies & Fire Daily Global 1km (MODIS/006/MOD14A1)\" map from Earth Engine. We'll use the band `FireMask` provided by the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a_xR5-c0ZhlN",
   "metadata": {
    "id": "a_xR5-c0ZhlN"
   },
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    'MODIS/006/MOD14A1': ['FireMask'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74921302-5977-4d63-9a04-a43c85909b4c",
   "metadata": {},
   "source": [
    "# BONEYARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66693140-860f-41d7-9616-a80a1ffa7d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m103"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
